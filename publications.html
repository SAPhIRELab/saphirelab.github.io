<!doctype html>
<html>

<head>
  <script src="https://kit.fontawesome.com/b9ee9badb1.js" crossorigin="anonymous"></script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
<meta name="Vasisht Duddu" content="">
<meta name="Vasisht Duddu" content="">
<script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>

<style>
.home {
  display: inline-block;
  background-color: #e9e9e9; /* light gray background */
  border-radius: 10px;       /* soft rounded corners */
  padding: 4px 10px;         /* balanced spacing */
  color: #b25d5d;            /* muted red text */
  font-weight: bold;
  font-size: 14px;
  font-family: 'Lato', sans-serif;
  text-decoration: none;     /* no underline */
}

.home2 {
  display: inline-block;
  background-color: #e9e9e9; /* light gray background */
  border-radius: 10px;       /* soft rounded corners */
  padding: 4px 10px;         /* balanced spacing */
  color: #b25d5d;            /* muted red text */
  font-weight: bold;
  font-size: 14px;
  font-family: 'Lato', sans-serif;
  text-decoration: none;     /* no underline */
  border: 1px solid #000;
}
  
.venue {
  background: rgba(250,235,215); /* white background */
  border-radius: 20px; /* pill shape */
  padding: 3px 6px; /* spacing inside */
  color: black; /* black text */
  font-size: 13px;
  font-weight: bold;
  font-family: "Lato", sans-serif;
  text-decoration: none; /* remove underline if link */
}

.award {
  background: rgba(175,214,155,0.7); /* black background */
  border-radius: 20px; /* pill shape */
  padding: 3px 6px; /* spacing inside */
  color: black; /* white text */
  font-size: 11px;
  font-weight: bold;
  font-family: "Lato", sans-serif;
  text-decoration: none; /* remove underline if link */
}

.paper {
  background: rgba(155,179,221,0.7); /* black background */
  border-radius: 20px; /* pill shape */
  padding: 3px 6px; /* spacing inside */
  color: black; /* white text */
  font-size: 11px;
  font-weight: bold;
  font-family: "Lato", sans-serif;
  text-decoration: none; /* remove underline if link */
}

.misc {
  background: rgba(255,201,5,0.7); /* black background */
  border-radius: 20px; /* pill shape */
  padding: 3px 6px; /* spacing inside */
  color: black; /* white text */
  font-size: 11px;
  font-weight: bold;
  font-family: "Lato", sans-serif;
  text-decoration: none; /* remove underline if link */
}

.code {
  background: rgba(234,102,119,0.7); /* black background */
  border-radius: 20px; /* pill shape */
  padding: 3px 6px; /* spacing inside */
  color: black; /* white text */
  font-size: 11px;
  font-weight: bold;
  font-family: "Lato", sans-serif;
  text-decoration: none; /* remove underline if link */
}

a .highlight {
  color: white; /* ensure white text color is applied inside the link */
}
</style>
  
<title>Vasisht Duddu</title>

<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
<link rel="shortcut icon" type="image/png" href="./images/favicon.png"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<style>

a:link {
  color: black;
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: black;
  background-color: transparent;
  text-decoration: underline;
}

.button {
  background-color: #414a4c;
  border: 1px solid black;
  color: white;
  padding: 0.5px 0.5px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 10px;
  margin: 1px 1px;
}

a.button {
  background-color: #414a4c;
  border: 1px solid black;
  color: white;
  padding: 0.5px 0.5px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 10px;
  font-weight: bold;
  margin: 1px 1px;
}

.button2 {
  background-color: #e7e7e7; color: black;
  border: 1px solid black;
  color: white;
  padding: 2px 4px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 13px;
  font-weight: bold;
  margin: 4px 2px;
}
</style>

<script type="text/javascript">
 function visibility_on(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'none')
          e.style.display = 'block';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'none')
          e.style.display = 'block';
 }
 function visibility_off(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'block')
          e.style.display = 'none';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'block')
          e.style.display = 'none';
 }
 function toggle_visibility(id) {
     var e = document.getElementById(id+"_text");
     if(e.style.display == 'inline')
        e.style.display = 'block';
     else
        e.style.display = 'inline';
     var e = document.getElementById(id+"_img");
     if(e.style.display == 'inline')
        e.style.display = 'block';
     else
        e.style.display = 'inline';
 }
 function toggle_vis(id) {
     var e = document.getElementById(id);
     if (e.style.display == 'none')
         e.style.display = 'inline';
     else
         e.style.display = 'none';
 }
</script>

</head>
<body>
<div class="wrapper">
<!--       <header>
<img src="./images/Aditya_new.png" height=150 width=150/><p/>
<a href="./index.html" style="color: #000000"><h1>Aditya Grover</h1></a><br/>
Email: adityag at cs.stanford.edu <br>
<a href="https://twitter.com/adityagrover_" class="twitter-follow-button" data-show-count="false" data-show-screen-name="false">Follow @adityagrover_</a>

</header> -->
<section>

<p>
<!--<img style="padding: 0 15px; float: left;" src="./images/Adi.png" height=175 width=150/>-->
<font size=6>Vasisht Duddu</font> <br>
<img src="./images/vasisht4.jpg" alt="Avatar">
Ph.D. Student, Computer Science<br>
<a  href="https://ssg-research.github.io/">Secure Systems Group</a> <br>
<a  href="https://cs.uwaterloo.ca/">University of Waterloo</a> <br>
<i class="fa fa-envelope"></i> vasisht.duddu at uwaterloo.ca <br>
</br>

<a href="https://scholar.google.com/citations?hl=en&user=oszzIkUAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" style="padding-left: 0px"><i class="ai ai-google-scholar-square ai-2x"></i></a>
<!--<a href="https://github.com/vasishtduddu" target="_blank" style="padding-left: 10px"><i class="fa fa-github-square fa-2x"></i></a>
<a href="https://gitlab.com/vasishtduddu" target="_blank" style="padding-left: 10px"><i class="fa fa-git-square fa-2x"></i></a>-->
<a href="https://x.com/vasishtduddu" target="_blank" style="padding-left: 10px"><i class="fa-brands fa-square-x-twitter fa-2x"></i></a>
<a href="https://bsky.app/profile/vasishtduddu.bsky.social" target="_blank" style="padding-left: 10px"><i class="fa-brands fa-square-bluesky fa-2x"></i></a>
<a href="https://www.linkedin.com/in/vduddu" target="_blank" style="padding-left: 10px"><i class="fa fa-linkedin-square fa-2x"></i></a>

</br>
</br>
<a href="vasishtduddu.github.io"><span class="home">Home</span></a> <a href="publications.html"><span class="home2">Publications</span></a> <a href="awards.html"><span class="home">Awards</span></a> <a href="talks.html"><span class="home">Talks</span></a> <a href="mentoring.html"><span class="home">Mentoring</span></a> <a href="pdfs/cv.pdf"><span class="home">CV</span></a> 
<!-- <button class="button button2"><a href="vasishtduddu.github.io">Home</a></button> <button class="button button2"><a href="publications.html">Publications</a></button> <button class="button button2"><a href="pdfs/cv.pdf">CV</a></button> -->
<!--<button class="button button2"><a href="talks.html">Talks</a></button> <button class="button button2"><a href="blog.html">Blog</a></button> -->
</p>

<!-- <button class="button button2"><a href="mentoring.html">Mentoring</a></button> -->

<hr style="border: 3px solid #f9f9f9; border-radius: 2px;">


<!--<h1>Publications</h1>-->



<b>Legend:</b> <span class="paper">Paper</span> <span class="venue" style="font-size: 11px">Venue</span> <span class="code">Code</span> <span class="misc">Miscellaneous</span> <span class="award"><i class='fas fa-award'></i> Award</span>  
<br>
<br>

<h3>Pre-Prints</h3>
<ul style="padding-left:15px;">

<li><u><b>Locket: Robust Feature-Locking Technique for Language Models</b></u> <a href="https://arxiv.org/abs/2510.12117"><span class="paper">Paper</span></a> <a href="#"><span class="code">Code</span></a> 
<br>
Lipeng He, <b><em>Vasisht Duddu</em></b>, N. Asokan
<br>
<a href="#"><span class="venue">Under Submission</span></a>
</li>
<br>
  
<li><u><b>PATCH: Mitigating PII Leakage in Language Models with Privacy-Aware Targeted Circuit Patching</b></u> <a href="https://arxiv.org/abs/2510.07452"><span class="paper">Paper</span></a> <a href="#"><span class="code">Code</span></a> 
<br>
Anthony Hughes, <b><em>Vasisht Duddu</em></b>, N. Asokan, Nikolaos Aletras, Ning Ma
<br>
<a href="#"><span class="venue">Under Submission</span></a>
</li>
<br>
  
<li><u><b>Amulet: A Python Library for Assessing Interactions Among ML Defenses and Risks</b></u> <a href="https://arxiv.org/abs/2509.12386"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/amulet"><span class="code">Code</span></a> 
<br>
Asim Waheed, <b><em>Vasisht Duddu</em></b>, Rui Zhang, Sebastian Szyller
<br>
<a href="#"><span class="venue">Under Submission</span></a> <span class="award"><i class='fas fa-award'></i> Technology Transfer to Intel</span>
</li>  
</ul> 

  
<h3>2026</h3>
<ul style="padding-left:15px;">
<li><u><b>Privacy Bias in Language Models: A Contextual Integrity-based Auditing Metric</b></u> <a href="https://arxiv.org/abs/2409.03735"><span class="paper">Paper</span></a>
<br>
Yan Shvartzshnaider, <b><em>Vasisht Duddu</em></b>
<br>
<a href="https://petsymposium.org/2026/paperlist.php"><span class="venue">Privacy Enhancing Technologies Symposium (PETS)</span></a>
<br>
<a href="https://ppai-workshop.github.io/#accepted_papers"><span class="venue">AAAI Workshop on Privacy-Preserving Artificial Intelligence (AAAI-PPAI)</span></a> <span class="award"><i class='fas fa-award'></i> Oral Presentation</span>
<!-- <a href="https://ppai-workshop.github.io/#accepted_papers" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">AAAI-PPAI</a> AAAI Workshop on Privacy-Preserving Artificial Intelligence  -->
</li>  
<br>
</ul>

  
<h3>2025</h3>
<ul style="padding-left:15px;">
<li><u><b> Combining Machine Learning Defenses without Conflicts</b></u> <a href="https://arxiv.org/abs/2411.09776"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/combining-defenses"><span class="code">Code</span></a>
<br>
<b><em>Vasisht Duddu</em></b>, Rui Zhang, N. Asokan
<br>
<a href="https://openreview.net/forum?id=C7FgsjfFRC"><span class="venue">Transactions on Machine Learning Research (TMLR)</span></a>
<!-- <a href="https://openreview.net/forum?id=C7FgsjfFRC" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">TMLR</a>  Transactions on Machine Learning Research -->
</li>  
<br>

  
<li><u><b>Position: Contextual Integrity is Inadequately Applied to Language Models</b></u> <a href="https://arxiv.org/abs/2501.19173"><span class="paper">Paper</span></a> 
<!--   <a href="https://arxiv.org/abs/2501.19173" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> -->
<br>
Yan Shvartzshnaider<sup>*</sup>, <b><em>Vasisht Duddu</em><sup>*</sup></b> (equal contribution)
<br>
<a href="https://openreview.net/forum?id=YmTxiR1HUX"><span class="venue">International Conference on Machine Learning (ICML)</span></a>
<!-- <a href="https://icml.cc/Conferences/2025" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">ICML</a> International Conference on Machine Learning -->
<br>
</li>  
<br>  
  
<li><u><b> Laminator: Verifiable ML Property Cards using Hardware-assisted Attestations</b></u> <a href="https://arxiv.org/abs/2406.17548"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/laminator"><span class="code">Code</span></a> <a href="https://sp2024.ieee-security.org/downloads/SP24-posters/sp24posters-final33.pdf"><span class="misc">Poster@IEEE S&P</span></a>
<br>
<b><em>Vasisht Duddu</em></b>, Oskari Järvinen, Lachlan J. Gunn, N. Asokan
<br>
<a href="https://www.codaspy.org/2025/"><span class="venue">ACM Conference on Data and Application Security and Privacy (CODASPY)</span></a>
<!-- <a href="https://www.codaspy.org/2025/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">ACM CODASPY</a> ACM Conference on Data and Application Security and Privacy -->
<!--
<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Trusted Hardware</button> <button class="button">Regulatory Compliance</button> <button class="button">Machine Learning</button>
-->
</li>  
<br>
  
<li style="background-color: #d8f5d1; padding: 10px; border-radius: 8px;"><u><b> Espresso: Robust Concept Filtering in Text-to-Image Models</b></u> <a href="https://arxiv.org/abs/2404.19227"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/concept-filtering"><span class="code">Code</span></a>
<!-- <br> -->
<!--   <a href="https://arxiv.org/abs/2404.19227" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/ssg-research/concept-filtering" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
Anudeep Das, <b><em>Vasisht Duddu</em></b>, Rui Zhang, N. Asokan
<br>
<a href="https://www.codaspy.org/2025/"><span class="venue">ACM Conference on Data and Application Security and Privacy (CODASPY)</span></a> <a href="https://cs.uwaterloo.ca/news/anudeep-das-vasisht-duddu-rui-zhang-n-asokan-win-best-paper-award-codaspy-2025"><span class="award"><i class='fas fa-award'></i> Best Paper Award</span></a>
<!-- <a href="https://www.codaspy.org/2025/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">ACM CODASPY</a> ACM Conference on Data and Application Security and Privacy <a href="https://cs.uwaterloo.ca/news/anudeep-das-vasisht-duddu-rui-zhang-n-asokan-win-best-paper-award-codaspy-2025"><span class="award"><i class='fas fa-award'></i> Best Paper Award</span></a> -->
<!--
<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Concept Removal</button> <button class="button">Adversarial Robustness</button> <button class="button">Diffusion Models</button>
-->
</li>  
</ul>  
  
<h3>2024</h3>
<ul style="padding-left:15px;">

<li style="background-color: #d8f5d1; padding: 10px; border-radius: 8px;"><b><u>SoK: Unintended Interactions among Machine Learning Defenses and Risks</u></b> <a href="https://arxiv.org/abs/2312.04542.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/sok-unintended-interactions"><span class="code">Code</span></a> <a href="https://blog.ssg.aalto.fi/2024/05/unintended-interactions-among-ml.html"><span class="misc">Blog</span></a>
<!--   <a href="https://arxiv.org/abs/2312.04542.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/ssg-research/sok-unintended-interactions" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> <a href="https://blog.ssg.aalto.fi/2024/05/unintended-interactions-among-ml.html" class="button" style="background-color: #cc6f00; font-weight: bolder; font-size:10px;">Blog</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Sebastian Szyller, N. Asokan
<br>
<a href="https://sp2024.ieee-security.org/"><span class="venue">IEEE Symposium on Security and Privacy (S&P)</span></a> <a href="https://cs.uwaterloo.ca/news/vasisht-duddu-sebastian-szyller-n-asokan-distinguished-paper-award-45th-ieee-symposium-security-and-privac"><span class="award"><i class='fas fa-award'></i> Distinguished Paper Award</span></a>
<!-- <a href="https://sp2024.ieee-security.org/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder ;font-size:10px;">IEEE S&P</a> IEEE Symposium on Security and Privacy (<i class='fas fa-award'></i><b><font color="#1263b3"> Distinguished Paper Award</font></b>) <a href="https://cs.uwaterloo.ca/news/vasisht-duddu-sebastian-szyller-n-asokan-distinguished-paper-award-45th-ieee-symposium-security-and-privacy" class="button" style="background-color: #cc6f00; font-weight: bolder; font-size:10px;">News</a> -->
<br>
<b>Industry Impact:</b> Amulet: Library for Evaluating Unintended Interactions <a href="https://github.com/ssg-research/amulet"><span class="code">Code</span></a> <span class="award"><i class='fas fa-award'></i> Technology Transfer to Intel</span>
<!--
<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Overfitting</button> <button class="button">Memorization</button> <button class="button">Trustworthy Machine Learning</button>  <button class="button">Systematization</button> 
-->
</li>
<br>
  
<li><b><u>GrOVe: Ownership Verification of Graph Neural Networks using Embeddings</u></b>  <a href="https://arxiv.org/abs/2304.08566.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/GrOVe"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2304.08566.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/ssg-research/GrOVe" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
Asim Waheed, <b><em>Vasisht Duddu</em></b>, N. Asokan
<br>
<a href="https://sp2024.ieee-security.org/"><span class="venue">IEEE Symposium on Security and Privacy (S&P)</span></a>
<!-- <a href="https://sp2024.ieee-security.org/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">IEEE S&P</a> IEEE Symposium on Security and Privacy -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Fingerprinting</button> <button class="button">Ownership Verification</button> <button class="button">Model Extraction Attacks</button> <button class="button">Graph Neural Networks</button>
-->
</li>
<br>
  
<li><b><u>Attesting Distributional Properties of Training Data for Machine Learning</u></b> <a href="https://arxiv.org/abs/2308.09552.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/ssg-research/distribution-attestation"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2308.09552.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/ssg-research/distribution-attestation" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Anudeep Das, Nora Khayata, Hossein Yalame, Thomas Schneider, N. Asokan
<br>
<a href="https://esorics2024.org/"><span class="venue">European Symposium on Research in Computer Security (ESORICS)</span></a>
<!-- <a href="https://esorics2024.org/" class="button" style="background-color: #1263b3; color: white;font-weight: bolder ;font-size:10px;">ESORICS</a> European Symposium on Research in Computer Security -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Regulatory Compliance</button> <button class="button">Distribution Inference</button> <button class="button">Cryptographic Attestation</button> <button class="button">Machine Learning</button>
-->
</li>  
<br>
  
<li><b><u>On the Alignment of Group Fairness with Attribute Privacy</u></b> <a href="https://arxiv.org/abs/2211.10209.pdf"><span class="paper">Paper</span></a>
<!--   <a href="https://arxiv.org/abs/2211.10209.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="#" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
Jan Aalmoes, <b><em>Vasisht Duddu</em></b>, Antoine Boutet
<br>
<a href="https://wise2024-qatar.com/"><span class="venue">International Web Information Systems Engineering Conference (WISE)</span></a>
<!-- <a href="https://wise2024-qatar.com/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">WISE</a> International Web Information Systems Engineering Conference -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Attribute Privacy</button> <button class="button">Inference Attacks</button> <button class="button">Algorithmic Fairness</button> <button class="button">Machine Learning</button>
-->
</li>
  
</ul>

<h3>2023</h3>
<ul style="padding-left:15px;">
<li><b><u>Comprehension from Chaos: What Users Understand and Expect from Private Computation</u></b> <a href="https://arxiv.org/abs/2211.07026.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/bkacsmar/MPC_InterviewStudy"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2211.07026.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/bkacsmar/MPC_InterviewStudy" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
Bailey Kacsmar, <b><em>Vasisht Duddu</em></b>, Kyle Tilbury, Blase Ur, Florian Kerschbaum
<br>
<a href="https://www.sigsac.org/ccs/CCS2023/"><span class="venue">ACM Conference on Computer and Communications Security (CCS)</span></a>
<!-- <a href="https://www.sigsac.org/ccs/CCS2023/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">ACM CCS</a> ACM Conference on Computer and Communications Security -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">User Study</button> <button class="button">Private Computation</button> <button class="button">Inference Attacks</button>
-->
</li>

</ul>

<h3>2022</h3>
<ul style="padding-left:15px;">  
<li><b><u>Inferring Sensitive Attributes from Model Explanations</u></b> <a href="https://arxiv.org/abs/2208.09967.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/vasishtduddu/AttInfExplanations"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2208.09967.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/vasishtduddu/AttInfExplanations" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Antoine Boutet
<br>
<a href="http://www.cikmconference.org/2022/"><span class="venue">ACM International Conference on Information and Knowledge Management (CIKM)</span></a>
<!-- <a href="http://www.cikmconference.org/2022/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">ACM CIKM</a> ACM International Conference on Information and Knowledge Management -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Attribute Privacy</button> <button class="button">Inference Attacks</button> <button class="button">Explainable Machine Learning</button> <button class="button">Deep Learning</button>
-->
</li>
<br>


<li><b><u>Towards Privacy Aware Deep Learning for Embedded Systems</u></b> <a href="https://arxiv.org/abs/2010.00912.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/vasishtduddu/EmbeddedMIA"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2010.00912.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/vasishtduddu/EmbeddedMIA" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Antoine Boutet, Virat Shejwalkar
<br>
<a href="https://www.sigapp.org/sac/sac2022/"><span class="venue">ACM Symposium On Applied Computing (SAC)</span></a> <a href="https://ppml-workshop.github.io/ppml20/index.html"><span class="venue">NeurIPS Workshop on PPML</span></a>
<!-- <a href="https://www.sigapp.org/sac/sac2022/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">ACM SAC</a> ACM Symposium On Applied Computing -->
<!-- <br> -->
<!-- <a href="https://ppml-workshop.github.io/ppml20/index.html" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">NeurIPS PPML</a> NeurIPS Workshop on Privacy Preserving Machine Learning -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Membership Privacy</button> <button class="button">Privacy by Design</button> <button class="button">Deep Learning</button>
-->
</li>
</ul>


<h3>2021</h3>
<ul style="padding-left:15px;">  
<!--
<li><b> SHAPr: An Efficient and Versatile Membership Privacy Risk Metric for Machine Learning </b> <a href="https://arxiv.org/abs/2112.02230.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="#" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a>
<br>
<b><em>Vasisht Duddu</em></b>, Sebastian Szyller, N. Asokan
<br>
<u>ArXiv Manuscript 2022</u>
<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Privacy Risk Metric</button> <button class="button">Membership Inference Attacks</button> <button class="button">Machine Learning</button>
</li>
<br>
 -->
  
<li><b><u>Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation GANs</u></b> <a href="https://arxiv.org/abs/2104.12623.pdf"><span class="paper">Paper</span></a> 
<!--   <a href="https://arxiv.org/abs/2104.12623.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> -->
<br>
Sebastian Szyller, <b><em>Vasisht Duddu</em></b>, Tommi Gröndahl, N. Asokan
<br>
<span class="venue">Technical Report</span>
<!-- <a href="#" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">Technical Report</a> -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Model Extraction Attack</button> <button class="button">Image Translation</button> <button class="button">Generative Adversarial Networks</button>
-->
</li>
</ul>

<h3>2020</h3>
<ul style="padding-left:15px;">  
<li><b><u>Quantifying Privacy Leakage in Graph Embedding</u></b> <a href="https://arxiv.org/abs/2010.00906.pdf"><span class="paper">Paper</span></a> <a href="https://github.com/vasishtduddu/GraphLeaks"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/2010.00906.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://github.com/vasishtduddu/GraphLeaks" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Antoine Boutet, Virat Shejwalkar
<br>
<a href="https://mobiquitous.eai-conferences.org/2020/call-for-papers/"><span class="venue">EAI International Conference on Mobile and Ubiquitous Systems (MobiQuitous)</span></a> <a href="https://ppml-workshop.github.io/ppml20/index.html"><span class="venue">NeurIPS Workshop on PPML</span></a>
<!-- <br> -->
<!-- <a href="https://ppml-workshop.github.io/ppml20/index.html" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">NeurIPS PPML</a> Workshop on Privacy Preserving Machine Learning -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Membership Privacy</button> <button class="button">Attribute Privacy</button> <button class="button">Graph Reconstruction</button> <button class="button">Graph Machine Learning</button>-->
<!--<a href="https://arxiv.org/abs/2010.00906.pdf"><i class="fas fa-file-pdf fa-2x" style="padding: 5px;"></i></a> <a href="https://doi.org/10.1145/3448891.3448939"><i class="ai ai-acm-square ai-2x" style="padding: 5px;"></i></a> <a href="https://github.com/vasishtduddu/GraphLeaks"><i class="fa fa-git-square fa-2x" style="padding: 5px;"></i></a> -->
</li>
<br>

<li><b><u>Fault Tolerance of Neural Networks in Adversarial Settings</u></b> <a href="https://arxiv.org/abs/1910.13875.pdf"><span class="paper">Paper</span></a> <a href="https://gitlab.com/vasishtduddu/FaultToleranceNoise"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/1910.13875.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://gitlab.com/vasishtduddu/FaultToleranceNoise" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, N. Rajesh Pillai, D. Vijay Rao, Valentina E. Balas
<br>
<a href="https://www.iospress.com/catalog/journals/journal-of-intelligent-fuzzy-systems"><span class="venue">Journal of Intelligent & Fuzzy Systems (JIFS)</span></a>
<!-- <a href="https://www.iospress.com/catalog/journals/journal-of-intelligent-fuzzy-systems" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">JIFS</a> Journal of Intelligent & Fuzzy Systems -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr;  <button class="button">Fault Tolerance</button> <button class="button">Differential Privacy</button> <button class="button">Adversarial Robustness</button> <button class="button">Deep Learning</button>
--><!-- <a href="https://arxiv.org/abs/1910.13875"><i class="fas fa-file-pdf fa-2x" style="padding: 5px;"></i></a> <a href="https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs179677"><i class="ai ai-doi-square ai-2x" style="padding: 5px;"></i></a> <a href="https://gitlab.com/vasishtduddu/FaultToleranceNoise"><i class="fa fa-git-square fa-2x" style="padding: 5px;"></i></a> -->
</li>
<br>
  
<li><b><u>Towards Enhancing Fault Tolerance in Neural Networks</u></b> <a href="https://arxiv.org/abs/1907.03103.pdf"><span class="paper">Paper</span></a> <a href="https://gitlab.com/vasishtduddu/FaultTolerantNN"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/1907.03103.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://gitlab.com/vasishtduddu/FaultTolerantNN" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, D. Vijay Rao, Valentina E. Balas
<br>
<a href="https://mobiquitous.eai-conferences.org/2020/call-for-papers/"><span class="venue">EAI International Conference on Mobile and Ubiquitous Systems (MobiQuitous)</span></a>
<!-- <a href="https://mobiquitous.eai-conferences.org/2020/call-for-papers/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">MobiQuitous</a> EAI International Conference on Mobile and Ubiquitous Systems -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr;  <button class="button">Fault Tolerance</button> <button class="button">Deep Learning</button>
-->
</li>
<br>

<li><b><u>Quantifying (Hyper) Parameter Leakage in Machine Learning</u></b> <a href="https://arxiv.org/abs/1910.14409.pdf"><span class="paper">Paper</span></a> <a href="https://gitlab.com/vasishtduddu/BayesModelExtraction"><span class="code">Code</span></a>
<!--   <a href="https://arxiv.org/abs/1910.14409.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> <a href="https://gitlab.com/vasishtduddu/BayesModelExtraction" class="button"; font-weight: bolder; font-size:10px;background-color: #FFC14D;">Code</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, D. Vijay Rao
<br>
<a href="http://bigmm.midas.iiitd.edu.in/"><span class="venue">IEEE International Conference on Multimedia Big Data (BigMM)</span></a>
<!-- <a href="http://bigmm.midas.iiitd.edu.in/" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">IEEE BigMM</a> IEEE International Conference on Multimedia Big Data -->
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr;  <button class="button">Model Extraction Attacks</button> <button class="button">Probabilistic Models</button> <button class="button">Deep Learning</button>
-->
</li>
</ul>


<h3>2018</h3>
<ul style="padding-left:15px;"> 
<li><b><u>Stealing Neural Networks via Timing Side Channels</u></b> <a href="https://arxiv.org/abs/1812.11720.pdf"><span class="paper">Paper</span></a>
<!--   <a href="https://arxiv.org/abs/1812.11720.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Debasis Samanta, D Vijay Rao, Valentina E. Balas
<br>
<span class="venue">Technical Report</span>
<!-- <a href="https://arxiv.org/abs/1812.11720.pdf" class="button" style="background-color: #1263b3; color: white; font-weight: bolder; font-size:10px;">Technical Report</a> -->
<!--
<u>Technical Report 2018 (Accepted for presentation in AI Village@DEFCON 27)</u>
<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Model Extraction Attack</button> <button class="button">Side Channel Leakage</button> <button class="button">Deep Learning</button>
-->
</li>
</ul>



<hr style="border: 3px solid #f9f9f9; border-radius: 2px;">

<h1>Theses</h1>

<ul style="padding-left:15px;">
<li><b><u>Towards Effective Measurement of Membership Privacy Risk for Machine Learning Models</u></b>  <a href="http://hdl.handle.net/10012/18448"><span class="paper">Thesis</span></a>
<!--   <a href="http://hdl.handle.net/10012/18448" class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Thesis</a> -->
<br>
<b><em>Vasisht Duddu</em></b>
<br>
<u>Master's Thesis, University of Waterloo, 2022</u>
<br>
<span class="venue">Technical Report</span> SHAPr: An Efficient and Versatile Membership Privacy Risk Metric for Machine Learning</u> <a href="https://arxiv.org/abs/2112.02230.pdf"><span class="paper">Paper</span></a>
<!--   <a href="https://arxiv.org/abs/2112.02230.pdf" class="button" style="background-color: #a52a2a; color: white; font-weight: bolder; font-size:10px;">Paper</a> -->
<br>
<b><em>Vasisht Duddu</em></b>, Sebastian Szyller, N. Asokan
<!--<br>
<button class="button" style="background-color: #a52a2a; color: white; font-weight: bold;">Keywords</button> &rArr; <button class="button">Data Privacy</button> <button class="button">Membership Privacy</button> <button class="button">Inference Attacks</button> <button class="button">Machine Learning</button>
-->
</li>
</ul>

</p>


<hr style="border: 3px solid #f9f9f9; border-radius: 2px;">


</div>

</body>
</html>
